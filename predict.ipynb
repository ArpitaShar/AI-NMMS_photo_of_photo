{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import load_learner\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "# from  utils import AlbumentationsTransform\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "import sys\n",
    "from fastai.vision.all import RandTransform,PILImage\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# #timm\n",
    "class AlbumentationsTransform(RandTransform):\n",
    "    \"A transform handler for multiple `Albumentation` transforms\"\n",
    "    split_idx,order=None,2\n",
    "    def __init__(self, train_aug, valid_aug):\n",
    "        store_attr()\n",
    "    \n",
    "    def before_call(self, b, split_idx):\n",
    "        self.idx = split_idx\n",
    "    \n",
    "    def encodes(self, img: PILImage):\n",
    "        if self.idx == 0:\n",
    "\n",
    "             aug_img = self.train_aug(image=np.array(img))['image']\n",
    "        \n",
    "        else:\n",
    "            aug_img = self.valid_aug(image=np.array(img))['image']\n",
    "        \n",
    "\n",
    "        return PILImage.create(aug_img)\n",
    "    \n",
    "\n",
    "# sys.modules['__main__'].AlbumentationsTransform = AlbumentationsTransform\n",
    "\n",
    "learner=load_learner(\"resenet34_64_368_20_v4_aug.pth\",cpu=True)\n",
    "\n",
    "sample_image_path='download - 2023-06-13T151500.690.png'\n",
    "a,b,c=learner.predict(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path of the directory containing images\n",
    "image_dir = r\"C:\\Users\\arpitasharma2\\OneDrive - Deloitte (O365D)\\Desktop\\DIU\\NMMS PHOTOS OF 10TH APRIL\\NMMS PHOTOS OF 10TH APRIL\"\n",
    "#loop through all the files in a directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith(('.jpg','.png','.jpeg')):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        if image is not None:\n",
    "            print(f\"loaded: {filename} - shape: {image.shape}\")\n",
    "        else:\n",
    "            print(f\"failed to load: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(float(c[1]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install fastai==2.7.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np>2\n",
    "# forcefully putting numpy 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.open(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "sample_image_path='download - 2023-06-13T151500.690.png'\n",
    "\n",
    "img=Image.open(sample_image_path)\n",
    "image= transform(img)\n",
    "image=image.permute(1, 2, 0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "learner=load_learner(r\"C:\\Users\\arpitasharma2\\OneDrive - Deloitte (O365D)\\Desktop\\DIU\\Classification\\Notebooks\\resenet34_64_368_20_v4_aug.pth\",cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(image_path, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Function to predict whether an image is recaptured or not based on the given image path.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): The path to the image file.\n",
    "    threshold (float, optional): The threshold probability above which an image is classified as recaptured. \n",
    "        Defaults to 0.85.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements:\n",
    "        - flag (int): A binary flag indicating whether the image is recaptured or not. \n",
    "            1 represents recaptured, and 0 represents not recaptured.\n",
    "        - recaptured_probability (float): The probability of the image being recaptured.\n",
    "    \n",
    "    Example:\n",
    "    >>> get_predictions('image.jpg')\n",
    "    (1, 0.92)\n",
    "    \"\"\"\n",
    "    _, _, probabilities = learner.predict(image_path)\n",
    "    \n",
    "    recaptured_probability = probabilities[1]\n",
    "    \n",
    "    flag = 1 if recaptured_probability >= threshold else 0\n",
    "    \n",
    "    return flag, float(recaptured_probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recaptured_probability=0.0000277751605608501\n",
    "THRESHOLD=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 1 if recaptured_probability >= THRESHOLD else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_path='download - 2023-06-13T151500.690.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.predict(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atifkhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(sample_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install albumentations==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "print(albumentations.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "transform = A.Compose([A.Resize(256, 256)])\n",
    "print(hasattr(transform, 'return_params'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your test images folder\n",
    "# image_folder = Path('/path/to/test_images')\n",
    "\n",
    "# # Loop over images\n",
    "# for img_path in image_folder.glob('*.*'):\n",
    "#     image = Image.open(img_path).convert('RGB')\n",
    "#     input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(input_tensor)\n",
    "#         _, predicted = torch.max(output, 1)\n",
    "\n",
    "#     print(f\"{img_path.name} => Predicted Class: {predicted.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
