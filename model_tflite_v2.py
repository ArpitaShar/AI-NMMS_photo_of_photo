# -*- coding: utf-8 -*-
"""model_tflite_v2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yBLWNM6atE01ajsojJwDRuvAl1IyOBqQ
"""

!pip install ai-edge-torch
# pip install ai-edge-torch==0.2.0

import ai_edge_torch
import numpy
import torch
import torchvision

from pathlib import Path
from torchvision.models import mobilenet_v2


# Set device (cpu or gpu)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load the model architecture
model = mobilenet_v2(pretrained=False)  # or your custom model
num_classes = 2  # adjust to your number of classes

# Modify last layer for your classes if needed
model.classifier[1] = torch.nn.Linear(model.last_channel, num_classes)

# Load saved weights
model_path = Path("/content/Model/mobilenet_student_distilled_1.pth")
if model_path.exists():
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    print("Model loaded successfully")
else:
    raise FileNotFoundError(f"Model not found at {model_path}")



# resnet18 = torchvision.models.resnet18(torchvision.models.ResNet18_Weights.IMAGENET1K_V1).eval()


sample_inputs = (torch.randn(1, 3, 256, 256),)
torch_output = model(*sample_inputs)

edge_model = ai_edge_torch.convert(model.eval(), sample_inputs)

edge_output = edge_model(*sample_inputs)


##########################################
if (numpy.allclose(
    torch_output.detach().numpy(),
    edge_output,
    atol=1e-5,
    rtol=1e-5,
)):
    print("Inference result with Pytorch and TfLite was within tolerance")
else:
    print("Something wrong with Pytorch --> TfLite")

from google.colab import files
edge_model.export('/content/MODEL_TFLITE/mobile_TEST.tflite')





